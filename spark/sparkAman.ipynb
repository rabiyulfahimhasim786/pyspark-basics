{"cells":[{"cell_type":"code","source":["from pyspark.sql import  SparkSession\nspark = SparkSession.builder.appName(\"test1\").getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3619bd04-ce47-4755-a198-8eaedff0fb60","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.read.csv(\"/FileStore/tables/employees.csv\" , header=True , inferSchema=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4f7b2986-3a04-4d50-a527-d7cfe7ea4e1d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# df2 = df.filter(df.Salary >60000)\ndf[\"Salary\"]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5be765bf-d79e-4c07-a3a0-5eb003be4d93","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# df[\"Salary\"]\n# df.Salary\ndf.select(\"Salary\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"894b5145-474c-47a9-b034-282d62f6bae3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[6]: DataFrame[Salary: int]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[6]: DataFrame[Salary: int]"]}}],"execution_count":0},{"cell_type":"code","source":["#filter condition\n# df.filter(df.Salary>60000).show()\n# df.filter(df[\"First Name\"]!=\"Aman\").show()\n# df.filter(df[\"First Name\"]==\"Douglas\").show()\n# df.filter(df[\"First Name\"]==\"Aman\").count()\n# df.filter(df[\"Gender\"]==\"Male\").count()\n# df.filter(df.Salary.isNull()).count()\n# df.filter(df.Salary.isNotNull()).count()\n# df.filter(df[\"First Name\"].like(\"%ama%\")).count()\n# df.filter(df.Team.isin([\"Marketing\",\"Finance\"])).count()\n# df.filter(df.Salary.between(60000,90000)).count()\n# df.filter(df[\"First Name\"].startswith(\"Doug\")).count()\n# df.filter(df[\"First Name\"].endswith(\"as\")).count()\n# df.filter(df[\"First Name\"].contains(\"as\")).count()\n# df.filter((df[\"Gender\"]==\"Male\")| (df[\"Team\"]==\"Marketing\")).count() -> pass multiple conditions\n# df.filter((df[\"Gender\"]==\"Male\")& (df[\"Team\"]==\"Marketing\")).count()\n# df.filter((df[\"Gender\"]==\"Male\")& (df[\"Team\"]==\"Marketing\"))\n\n# not equals condition\n# df.filter(df.Team != \"OH\").show() \n# df.filter(~(df.state == \"OH\")).show()\n\n#Using SQL col() function\n# from pyspark.sql.functions import col\n# df.filter(col(\"state\") == \"OH\").show() \n\n#Using SQL Expression\n# df.filter(\"gender == 'M'\").show()\n#For not equal\n# df.filter(\"gender != 'M'\").show()\n# df.filter(\"gender <> 'M'\").show()\n\n# Filter NOT IS IN List values\n#These show all records with NY (NY is not part of the list)\n# li = [\"Marketing\",\"Legal\",\"Product\"]\n# df.filter(~df.Team.isin(li)).count()\n# df.filter(df.Team.isin(li)==False).show()\n\n# rlike - SQL RLIKE pattern (LIKE with Regex)\n#This check case insensitive\n# df2.filter(df2.name.rlike(\"(?i)^*rose$\")).show()\n\n# rom pyspark.sql.types import StructType,StructField \n# from pyspark.sql.types import StringType, IntegerType, ArrayType\n# data = [\n#     ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n#     ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n#     ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n#     ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n#     ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n#     ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n#  ]\n        \n# schema = StructType([\n#      StructField('name', StructType([\n#         StructField('firstname', StringType(), True),\n#         StructField('middlename', StringType(), True),\n#          StructField('lastname', StringType(), True)\n#      ])),\n#      StructField('languages', ArrayType(StringType()), True),\n#      StructField('state', StringType(), True),\n#      StructField('gender', StringType(), True)\n#  ])\n\n# df = spark.createDataFrame(data = data, schema = schema)\n# df.printSchema()\n\n#Filter from arrays\n# from pyspark.sql.functions import array_contains\n# df.filter(array_contains(df.languages,\"Java\")).show(truncate=False) \n\n#Filter on Nested Structer \n# df.filter(df.name.lastname == \"Williams\").show(truncate=False) \n\n# where() clause instead of the filter() if you are coming from an SQL background, both these functions operate exactly the same.\n# df.where(df.Salary == 28000).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"04027ca0-6bb6-49a6-9b06-9299ef463f5f","inputWidgets":{},"title":"Filter and Where DataFrame"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[8]: 1000","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[8]: 1000"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructType,StructField \nfrom pyspark.sql.types import StringType, IntegerType, ArrayType\ndata = [\n    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n ]\n        \nschema = StructType([\n     StructField('name', StructType([\n        StructField('firstname', StringType(), True),\n        StructField('middlename', StringType(), True),\n         StructField('lastname', StringType(), True)\n     ])),\n     StructField('languages', ArrayType(StringType()), True),\n     StructField('state', StringType(), True),\n     StructField('gender', StringType(), True)\n ])\ndf = spark.createDataFrame(data = data, schema = schema)\ndf.printSchema()\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e73701b7-db09-4732-ac54-13c33c7d32ea","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- languages: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- state: string (nullable = true)\n |-- gender: string (nullable = true)\n\n+--------------------+------------------+-----+------+\n|                name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n| {Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n+--------------------+------------------+-----+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- languages: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- state: string (nullable = true)\n |-- gender: string (nullable = true)\n\n+--------------------+------------------+-----+------+\n|                name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n| {Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n+--------------------+------------------+-----+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# df.filter(df.name.lastname == \"Williams\").show()\nfrom pyspark.sql.functions import array_contains\ndf.filter(array_contains(df.languages,\"Java\")).show() \n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a18cff14-a9a1-4b96-b4d8-e5c33cb96344","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------------+------------------+-----+------+\n|name            |languages         |state|gender|\n+----------------+------------------+-----+------+\n|{James, , Smith}|[Java, Scala, C++]|OH   |M     |\n|{Anna, Rose, }  |[Spark, Java, C++]|NY   |F     |\n+----------------+------------------+-----+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------------+------------------+-----+------+\n|name            |languages         |state|gender|\n+----------------+------------------+-----+------+\n|{James, , Smith}|[Java, Scala, C++]|OH   |M     |\n|{Anna, Rose, }  |[Spark, Java, C++]|NY   |F     |\n+----------------+------------------+-----+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.where(\"First Name\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0d5f783d-cbcc-4a5a-89bc-17c1a51cb591","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[127]: DataFrame[First Name: string, Gender: string, Start Date: string, Last Login Time: string, Salary: int, Bonus %: double, Senior Management: boolean, Team: string, New Column: string, Salary In String: int]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[127]: DataFrame[First Name: string, Gender: string, Start Date: string, Last Login Time: string, Salary: int, Bonus %: double, Senior Management: boolean, Team: string, New Column: string, Salary In String: int]"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import lit  , col\n# df = df.withColumn(\"New Column\",lit(\"New Value\")) --> Add a new column\n# df.show()\n# df.printSchema()\n# df = df.withColumn(\"Salary In String\",col(\"Salary\").cast(\"String\")) #--> Add new column with salary string \n\n# df = df.withColumn(\"Salary In String\",col(\"Salary\").cast(\"Integer\")) --> Change the data type of column using cas function\n# df.printSchema()\n# df.withColumn(\"salary\",col(\"salary\")*100).show() --> update the existing value of the column \n# df.withColumn(\"CopiedColumn\",col(\"salary\")* -1).show() -->  Create a Column from an Existing\n# df.withColumnRenamed(\"gender\",\"sex\").show() \n# df.drop(\"New Column\").show()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"8f0cdf64-0851-4e89-a1d1-3daed03d7bee","inputWidgets":{},"title":"Add Column , Delete Column , Rename Column"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+------+----------+---------------+------+-------+-----------------+--------------------+----------+----------------+\n|First Name|sex   |Start Date|Last Login Time|Salary|Bonus %|Senior Management|Team                |New Column|Salary In String|\n+----------+------+----------+---------------+------+-------+-----------------+--------------------+----------+----------------+\n|Douglas   |Male  |8/6/1993  |12:42 PM       |97308 |6.945  |true             |Marketing           |New Value |97308           |\n|Thomas    |Male  |3/31/1996 |6:53 AM        |61933 |4.17   |true             |null                |New Value |61933           |\n|Maria     |Female|4/23/1993 |11:17 AM       |130590|11.858 |false            |Finance             |New Value |130590          |\n|Jerry     |Male  |3/4/2005  |1:00 PM        |138705|9.34   |true             |Finance             |New Value |138705          |\n|Larry     |Male  |1/24/1998 |4:47 PM        |101004|1.389  |true             |Client Services     |New Value |101004          |\n|Dennis    |Male  |4/18/1987 |1:35 AM        |115163|10.125 |false            |Legal               |New Value |115163          |\n|Ruby      |Female|8/17/1987 |4:20 PM        |65476 |10.012 |true             |Product             |New Value |65476           |\n|null      |Female|7/20/2015 |10:43 AM       |45906 |11.598 |null             |Finance             |New Value |45906           |\n|Angela    |Female|11/22/2005|6:29 AM        |95570 |18.523 |true             |Engineering         |New Value |95570           |\n|Frances   |Female|8/8/2002  |6:51 AM        |139852|7.524  |true             |Business Development|New Value |139852          |\n|Louise    |Female|8/12/1980 |9:01 AM        |63241 |15.132 |true             |null                |New Value |63241           |\n|Julie     |Female|10/26/1997|3:19 PM        |102508|12.637 |true             |Legal               |New Value |102508          |\n|Brandon   |Male  |12/1/1980 |1:08 AM        |112807|17.492 |true             |Human Resources     |New Value |112807          |\n|Gary      |Male  |1/27/2008 |11:40 PM       |109831|5.831  |false            |Sales               |New Value |109831          |\n|Kimberly  |Female|1/14/1999 |7:13 AM        |41426 |14.543 |true             |Finance             |New Value |41426           |\n|Lillian   |Female|6/5/2016  |6:09 AM        |59414 |1.256  |false            |Product             |New Value |59414           |\n|Jeremy    |Male  |9/21/2010 |5:56 AM        |90370 |7.369  |false            |Human Resources     |New Value |90370           |\n|Shawn     |Male  |12/7/1986 |7:45 PM        |111737|6.414  |false            |Product             |New Value |111737          |\n|Diana     |Female|10/23/1981|10:27 AM       |132940|19.082 |false            |Client Services     |New Value |132940          |\n|Donna     |Female|7/22/2010 |3:48 AM        |81014 |1.894  |false            |Product             |New Value |81014           |\n+----------+------+----------+---------------+------+-------+-----------------+--------------------+----------+----------------+\nonly showing top 20 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+------+----------+---------------+------+-------+-----------------+--------------------+----------+----------------+\n|First Name|sex   |Start Date|Last Login Time|Salary|Bonus %|Senior Management|Team                |New Column|Salary In String|\n+----------+------+----------+---------------+------+-------+-----------------+--------------------+----------+----------------+\n|Douglas   |Male  |8/6/1993  |12:42 PM       |97308 |6.945  |true             |Marketing           |New Value |97308           |\n|Thomas    |Male  |3/31/1996 |6:53 AM        |61933 |4.17   |true             |null                |New Value |61933           |\n|Maria     |Female|4/23/1993 |11:17 AM       |130590|11.858 |false            |Finance             |New Value |130590          |\n|Jerry     |Male  |3/4/2005  |1:00 PM        |138705|9.34   |true             |Finance             |New Value |138705          |\n|Larry     |Male  |1/24/1998 |4:47 PM        |101004|1.389  |true             |Client Services     |New Value |101004          |\n|Dennis    |Male  |4/18/1987 |1:35 AM        |115163|10.125 |false            |Legal               |New Value |115163          |\n|Ruby      |Female|8/17/1987 |4:20 PM        |65476 |10.012 |true             |Product             |New Value |65476           |\n|null      |Female|7/20/2015 |10:43 AM       |45906 |11.598 |null             |Finance             |New Value |45906           |\n|Angela    |Female|11/22/2005|6:29 AM        |95570 |18.523 |true             |Engineering         |New Value |95570           |\n|Frances   |Female|8/8/2002  |6:51 AM        |139852|7.524  |true             |Business Development|New Value |139852          |\n|Louise    |Female|8/12/1980 |9:01 AM        |63241 |15.132 |true             |null                |New Value |63241           |\n|Julie     |Female|10/26/1997|3:19 PM        |102508|12.637 |true             |Legal               |New Value |102508          |\n|Brandon   |Male  |12/1/1980 |1:08 AM        |112807|17.492 |true             |Human Resources     |New Value |112807          |\n|Gary      |Male  |1/27/2008 |11:40 PM       |109831|5.831  |false            |Sales               |New Value |109831          |\n|Kimberly  |Female|1/14/1999 |7:13 AM        |41426 |14.543 |true             |Finance             |New Value |41426           |\n|Lillian   |Female|6/5/2016  |6:09 AM        |59414 |1.256  |false            |Product             |New Value |59414           |\n|Jeremy    |Male  |9/21/2010 |5:56 AM        |90370 |7.369  |false            |Human Resources     |New Value |90370           |\n|Shawn     |Male  |12/7/1986 |7:45 PM        |111737|6.414  |false            |Product             |New Value |111737          |\n|Diana     |Female|10/23/1981|10:27 AM       |132940|19.082 |false            |Client Services     |New Value |132940          |\n|Donna     |Female|7/22/2010 |3:48 AM        |81014 |1.894  |false            |Product             |New Value |81014           |\n+----------+------+----------+---------------+------+-------+-----------------+--------------------+----------+----------------+\nonly showing top 20 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# PySpark, select() function is used to select single, multiple, column by index, all columns ,\n# df.select([\"First Name\",\"Gender\"]).show()\n# df.select(col(\"Gender\"),col(\"Salary\")).show() --> Another way \n# df.select(df.colRegex(\"`^.*name*`\")).show() --> regex can also be use in select\n\n#select all columns multiple ways \n# df.select(*columns).show()\n# df.select([col for col in df.columns]).show()\n# df.select(\"*\").show()\n\n#Select Column index wise\n# df.select(df.columns[:3]).show(3)\n# df.select(df.columns[2:4]).show(3)\n\n#Select nested columns\n# df2.select(\"name.firstname\",\"name.lastname\")."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"c1342295-1dde-4938-9759-af8582e4eed4","inputWidgets":{},"title":"Select"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+------+------+\n|Gender|Salary|\n+------+------+\n|  Male| 97308|\n|  Male| 61933|\n|Female|130590|\n|  Male|138705|\n|  Male|101004|\n|  Male|115163|\n|Female| 65476|\n|Female| 45906|\n|Female| 95570|\n|Female|139852|\n|Female| 63241|\n|Female|102508|\n|  Male|112807|\n|  Male|109831|\n|Female| 41426|\n|Female| 59414|\n|  Male| 90370|\n|  Male|111737|\n|Female|132940|\n|Female| 81014|\n+------+------+\nonly showing top 20 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------+------+\n|Gender|Salary|\n+------+------+\n|  Male| 97308|\n|  Male| 61933|\n|Female|130590|\n|  Male|138705|\n|  Male|101004|\n|  Male|115163|\n|Female| 65476|\n|Female| 45906|\n|Female| 95570|\n|Female|139852|\n|Female| 63241|\n|Female|102508|\n|  Male|112807|\n|  Male|109831|\n|Female| 41426|\n|Female| 59414|\n|  Male| 90370|\n|  Male|111737|\n|Female|132940|\n|Female| 81014|\n+------+------+\nonly showing top 20 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# df.collect() retrieves all elements in a DataFrame as an Array\n#Returns value of First Row, First Column which is \"Finance\"\n# df.collect()[0][0]\n# df.collect() returns Array of Row type.\n# df.collect()[0] returns the first element in an array (1st row).\n# df.collect[0][0] returns the value of the first row & first column."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"dd5b16d7-8e46-4c29-bff3-c9f0936d3bfb","inputWidgets":{},"title":"Collect()"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#get distinct values\n# df.distinct().count()\n# df.select(\"Salary\").distinct().count() #get count of particular column\n\n#to drop duplicates \n# df.dropDuplicates()\n# df.dropDuplicates([\"First Name\"]).count()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"98203150-addf-4fbc-a0ca-09d24f1689ac","inputWidgets":{},"title":"Duplicates"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[137]: 201","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[137]: 201"]}}],"execution_count":0},{"cell_type":"code","source":["# df.sort(\"Salary\").show()\n# df.sort(col(\"department\"),col(\"state\")).show()\n# df.sort(df.Salary.asc()).asc().show()\n# df.sort(df.Salary.asc(),df.Bonus.asc()).show()\n# df.sort(col(\"department\").asc(),col(\"state\").asc()).show()\n# df.sort(df.department.asc(),df.state.desc()).show()\n# df.sort(col(\"department\").asc(),col(\"state\").desc()).show()\n\n#Order by\n# df.orderBy(\"Salary\").show()\n# df.orderBy(\"department\",\"state\").show()\n# df.orderBy(col(\"department\"),col(\"state\")).show()\n# df.orderBy(col(\"department\").asc(),col(\"state\").asc()).show()\n# df.orderBy(col(\"department\").asc(),col(\"state\").desc()).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"e9aafca5-c515-4772-a94c-1db64ef0bb2e","inputWidgets":{},"title":"Order By and Sort by"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+------+----------+---------------+------+-------+-----------------+--------------------+----------+----------------+\n|First Name|Gender|Start Date|Last Login Time|Salary|Bonus %|Senior Management|                Team|New Column|Salary In String|\n+----------+------+----------+---------------+------+-------+-----------------+--------------------+----------+----------------+\n|   Michael|  Male| 7/30/1993|        5:35 PM| 35013| 14.879|            false|             Product| New Value|           35013|\n|     Kevin|  Male| 3/25/1982|        7:31 AM| 35061|  5.128|            false|               Legal| New Value|           35061|\n|    Steven|  Male| 3/30/1980|        9:20 PM| 35095|  8.379|             true|     Client Services| New Value|           35095|\n|   Matthew|  Male|  1/2/2013|       10:33 PM| 35203|  18.04|            false|     Human Resources| New Value|           35203|\n|   Cynthia|Female|  7/5/1986|        1:24 AM| 35381| 11.749|            false|             Finance| New Value|           35381|\n| Christina|Female| 6/23/2002|        3:18 PM| 35477| 18.178|            false|     Human Resources| New Value|           35477|\n|  Kathleen|Female| 6/13/2014|        9:16 AM| 35575| 14.595|            false|        Distribution| New Value|           35575|\n|     Terry|  Male|11/10/2004|        4:33 AM| 35633|  3.947|             true|        Distribution| New Value|           35633|\n|     Bruce|  Male|  5/7/1980|        8:00 PM| 35802| 12.391|             true|               Sales| New Value|           35802|\n|   Frances|Female| 5/16/2014|        8:31 AM| 35884| 17.667|            false|               Sales| New Value|           35884|\n|     Maria|Female|12/27/1990|        9:57 PM| 36067|   9.64|             true|             Product| New Value|           36067|\n|     Julia|Female|  3/2/1982|       12:52 PM| 36403|  2.664|             true|             Finance| New Value|           36403|\n|  Kimberly|Female| 7/15/1997|        5:57 AM| 36643|  7.953|            false|           Marketing| New Value|           36643|\n|    Denise|Female| 3/18/2001|       12:02 AM| 36697| 11.196|             true|               Sales| New Value|           36697|\n|     Emily|Female| 1/13/1988|        6:42 AM| 36711| 19.028|             true|     Human Resources| New Value|           36711|\n|    George|  Male| 9/27/1995|        5:04 PM| 36749| 19.754|            false|             Finance| New Value|           36749|\n|    Evelyn|Female|  9/3/1983|        1:58 PM| 36759| 17.269|             true|           Marketing| New Value|           36759|\n|   Phillip|  Male| 10/7/1984|       11:05 AM| 36837|  14.66|            false|           Marketing| New Value|           36837|\n| Stephanie|Female| 9/13/1986|        1:52 AM| 36844|  5.574|             true|Business Development| New Value|           36844|\n|     Janet|Female| 7/12/2008|       12:10 PM| 36927| 18.769|            false|     Client Services| New Value|           36927|\n+----------+------+----------+---------------+------+-------+-----------------+--------------------+----------+----------------+\nonly showing top 20 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+------+----------+---------------+------+-------+-----------------+--------------------+----------+----------------+\n|First Name|Gender|Start Date|Last Login Time|Salary|Bonus %|Senior Management|                Team|New Column|Salary In String|\n+----------+------+----------+---------------+------+-------+-----------------+--------------------+----------+----------------+\n|   Michael|  Male| 7/30/1993|        5:35 PM| 35013| 14.879|            false|             Product| New Value|           35013|\n|     Kevin|  Male| 3/25/1982|        7:31 AM| 35061|  5.128|            false|               Legal| New Value|           35061|\n|    Steven|  Male| 3/30/1980|        9:20 PM| 35095|  8.379|             true|     Client Services| New Value|           35095|\n|   Matthew|  Male|  1/2/2013|       10:33 PM| 35203|  18.04|            false|     Human Resources| New Value|           35203|\n|   Cynthia|Female|  7/5/1986|        1:24 AM| 35381| 11.749|            false|             Finance| New Value|           35381|\n| Christina|Female| 6/23/2002|        3:18 PM| 35477| 18.178|            false|     Human Resources| New Value|           35477|\n|  Kathleen|Female| 6/13/2014|        9:16 AM| 35575| 14.595|            false|        Distribution| New Value|           35575|\n|     Terry|  Male|11/10/2004|        4:33 AM| 35633|  3.947|             true|        Distribution| New Value|           35633|\n|     Bruce|  Male|  5/7/1980|        8:00 PM| 35802| 12.391|             true|               Sales| New Value|           35802|\n|   Frances|Female| 5/16/2014|        8:31 AM| 35884| 17.667|            false|               Sales| New Value|           35884|\n|     Maria|Female|12/27/1990|        9:57 PM| 36067|   9.64|             true|             Product| New Value|           36067|\n|     Julia|Female|  3/2/1982|       12:52 PM| 36403|  2.664|             true|             Finance| New Value|           36403|\n|  Kimberly|Female| 7/15/1997|        5:57 AM| 36643|  7.953|            false|           Marketing| New Value|           36643|\n|    Denise|Female| 3/18/2001|       12:02 AM| 36697| 11.196|             true|               Sales| New Value|           36697|\n|     Emily|Female| 1/13/1988|        6:42 AM| 36711| 19.028|             true|     Human Resources| New Value|           36711|\n|    George|  Male| 9/27/1995|        5:04 PM| 36749| 19.754|            false|             Finance| New Value|           36749|\n|    Evelyn|Female|  9/3/1983|        1:58 PM| 36759| 17.269|             true|           Marketing| New Value|           36759|\n|   Phillip|  Male| 10/7/1984|       11:05 AM| 36837|  14.66|            false|           Marketing| New Value|           36837|\n| Stephanie|Female| 9/13/1986|        1:52 AM| 36844|  5.574|             true|Business Development| New Value|           36844|\n|     Janet|Female| 7/12/2008|       12:10 PM| 36927| 18.769|            false|     Client Services| New Value|           36927|\n+----------+------+----------+---------------+------+-------+-----------------+--------------------+----------+----------------+\nonly showing top 20 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["\"\"\"\nWhen we perform groupBy() on PySpark Dataframe, it returns GroupedData object which contains below aggregate functions.\ncount() – Use groupBy() count() to return the number of rows for each group.\nmean() – Returns the mean of values for each group.\nmax() – Returns the maximum of values for each group.\nmin() – Returns the minimum of values for each group.\nsum() – Returns the total for values for each group.\navg() – Returns the average for values for each group.\nagg() – Using groupBy() agg() function, we can calculate more than one aggregate at a time.\n\"\"\"\n\n# df.groupBy(\"Team\").sum(\"Salary\").show()\n# //GroupBy on multiple columns\n# df.groupBy(\"department\",\"state\").sum(\"salary\",\"bonus\").show()\n\n#agg \n# from pyspark.sql.functions import sum,avg,max\n# df.groupBy(\"department\").agg(sum(\"salary\").alias(\"sum_salary\"),avg(\"salary\").alias(\"avg_salary\"),sum(\"bonus\").alias(\"sum_bonus\"),max(\"bonus\").alias(\"max_bonus\")).show()\n\n#using condition\n# from pyspark.sql.functions import sum,avg,max\n# df.groupBy(\"department\") \\\n#     .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n#       avg(\"salary\").alias(\"avg_salary\"), \\\n#       sum(\"bonus\").alias(\"sum_bonus\"), \\\n#       max(\"bonus\").alias(\"max_bonus\")) \\\n#     .where(col(\"sum_bonus\") >= 50000) \\\n#     .show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"057e73f7-a51c-4f93-8a32-c4f137dd6ca7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#inner join\n# empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"inner\").show()\n\n#left join \n# empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"left\").show()\n\n#right join \n# empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"right\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"5309fc27-92d6-48cb-943e-04a1dc88aaea","inputWidgets":{},"title":"Inner Join "}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\"\"\"\nLet’s convert upperCase() python function to UDF and then use it with DataFrame withColumn(). Below example converts the values of “Name” column to upper case and creates a new column “Curated Name”\n\n\"\"\"\n# def upperCase(str):\n#     return str.upper()\n\n\n# upperCaseUDF = udf(lambda z:upperCase(z),StringType())   \n\n# df.withColumn(\"Cureated Name\", upperCaseUDF(col(\"Name\"))).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"5df4f39c-81bc-4fb6-b902-8581085cd195","inputWidgets":{},"title":"Pyspark UDF"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"35c3b024-e87c-4995-8ea0-1b5cb583a39a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dd57a3d4-e2b9-454a-ae86-f06c9e1b4ae1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ce96eb37-a7df-4408-b1fc-8067c097d0ef","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#count the columns who have null values \nfrom pyspark.sql.functions import isnan, when, count, col\ndf.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d8e905c2-fb74-43b7-bca0-3965fdd7069a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----+----+------+--------+---+------+------+-------+------+\n|Name|Team|Number|Position|Age|Height|Weight|College|Salary|\n+----+----+------+--------+---+------+------+-------+------+\n|   1|   1|     1|       1|  1|     1|     1|     85|    12|\n+----+----+------+--------+---+------+------+-------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+----+------+--------+---+------+------+-------+------+\n|Name|Team|Number|Position|Age|Height|Weight|College|Salary|\n+----+----+------+--------+---+------+------+-------+------+\n|   1|   1|     1|       1|  1|     1|     1|     85|    12|\n+----+----+------+--------+---+------+------+-------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"28ce3de7-d77f-4175-be27-378e44fc5af0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-1131491803534067>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m#count for particula column\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mwhen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcol\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Salary\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misNull\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/functions.py\u001B[0m in \u001B[0;36mwhen\u001B[0;34m(condition, value)\u001B[0m\n\u001B[1;32m   1604\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"condition should be a Column\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1605\u001B[0m     \u001B[0mv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jc\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mColumn\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1606\u001B[0;31m     \u001B[0mjc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jvm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunctions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwhen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcondition\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1607\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mColumn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1608\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1294\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1295\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1296\u001B[0;31m         \u001B[0margs_command\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_build_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1297\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1298\u001B[0m         \u001B[0mcommand\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mproto\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCALL_COMMAND_NAME\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m_build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1265\u001B[0m         args_command = \"\".join(\n\u001B[0;32m-> 1266\u001B[0;31m             [get_command_part(arg, self.pool) for arg in new_args])\n\u001B[0m\u001B[1;32m   1267\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1268\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0margs_command\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1265\u001B[0m         args_command = \"\".join(\n\u001B[0;32m-> 1266\u001B[0;31m             [get_command_part(arg, self.pool) for arg in new_args])\n\u001B[0m\u001B[1;32m   1267\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1268\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0margs_command\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_command_part\u001B[0;34m(parameter, python_proxy_pool)\u001B[0m\n\u001B[1;32m    296\u001B[0m             \u001B[0mcommand_part\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34m\";\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0minterface\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    297\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 298\u001B[0;31m         \u001B[0mcommand_part\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mparameter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_object_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m     \u001B[0mcommand_part\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34m\"\\n\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1798\u001B[0m         \"\"\"\n\u001B[1;32m   1799\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1800\u001B[0;31m             raise AttributeError(\n\u001B[0m\u001B[1;32m   1801\u001B[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001B[1;32m   1802\u001B[0m         \u001B[0mjc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute '_get_object_id'","errorSummary":"<span class='ansi-red-fg'>AttributeError</span>: 'DataFrame' object has no attribute '_get_object_id'","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-1131491803534067>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m#count for particula column\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mwhen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcol\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Salary\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misNull\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/functions.py\u001B[0m in \u001B[0;36mwhen\u001B[0;34m(condition, value)\u001B[0m\n\u001B[1;32m   1604\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"condition should be a Column\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1605\u001B[0m     \u001B[0mv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jc\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mColumn\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1606\u001B[0;31m     \u001B[0mjc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jvm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunctions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwhen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcondition\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1607\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mColumn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1608\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1294\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1295\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1296\u001B[0;31m         \u001B[0margs_command\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_build_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1297\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1298\u001B[0m         \u001B[0mcommand\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mproto\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCALL_COMMAND_NAME\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m_build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1265\u001B[0m         args_command = \"\".join(\n\u001B[0;32m-> 1266\u001B[0;31m             [get_command_part(arg, self.pool) for arg in new_args])\n\u001B[0m\u001B[1;32m   1267\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1268\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0margs_command\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1265\u001B[0m         args_command = \"\".join(\n\u001B[0;32m-> 1266\u001B[0;31m             [get_command_part(arg, self.pool) for arg in new_args])\n\u001B[0m\u001B[1;32m   1267\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1268\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0margs_command\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_args\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_command_part\u001B[0;34m(parameter, python_proxy_pool)\u001B[0m\n\u001B[1;32m    296\u001B[0m             \u001B[0mcommand_part\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34m\";\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0minterface\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    297\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 298\u001B[0;31m         \u001B[0mcommand_part\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mparameter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_object_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m     \u001B[0mcommand_part\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34m\"\\n\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1798\u001B[0m         \"\"\"\n\u001B[1;32m   1799\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1800\u001B[0;31m             raise AttributeError(\n\u001B[0m\u001B[1;32m   1801\u001B[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001B[1;32m   1802\u001B[0m         \u001B[0mjc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute '_get_object_id'"]}}],"execution_count":0},{"cell_type":"code","source":["\"\"\"My name is aman my contact is 7777777777 i have another phone my contact for other phone is 8888888888 , \njksfb 555555555 jsbfjkb jbs fjs fjs fsj fskjf 44444444444 \"\"\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f01005fb-cca9-48f3-962f-29875897a2c1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#sql files \n#temptables \n#views \n#index \n\"\"\"\ncreate view viewname()\n\n;\n\ncreate temptable table \n#aman-A_@aman.com\n\n\"\"\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"781f66dc-c8d9-4152-bdb2-7634697fdd62","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ced7e30b-0c3c-46f5-9bef-c2c70f97c601","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6c4c07c8-5d2a-41a9-ba12-cfceb317ee11","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b6edb66b-288e-4225-b240-80eb9da585a3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5519348d-6c66-48c7-a366-46650f90db57","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b359bc7b-cfbd-42ce-9170-41ee7f48f45a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fccc7586-e32c-4563-a6f4-cfb42414c7c3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8793f2f7-6b46-449c-b085-a54f595a2fa9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f688080d-4eae-4fdd-a27c-0ff434bde4b8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"114780f5-6f3d-41cb-980f-2cc8397e1d82","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"50bd00df-1322-4bc4-9710-d79c1756944a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b7efd6d8-65d9-484c-b1c6-fdd024ad62b9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"19b14d27-be9c-42fe-9049-6b7b129d0ef5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"89c5c260-b12c-4451-b891-55d422677d50","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"08d4d07b-472d-4a27-994c-677aebfeb307","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"174d1632-3338-4a6d-b0e1-4419c7110bb9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"345f3a1d-d45f-4ee7-b701-6226d9e7862b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c037dad4-d265-4d93-b3e0-100153654226","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8a79365d-9e56-4f9a-9623-77c8a736a7cd","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4934af73-f689-4f6d-8356-8633d7e937f3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b3f731e4-825f-46ca-a4d4-9c7d53a603da","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"sparkAman","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1586558290681960}},"nbformat":4,"nbformat_minor":0}
